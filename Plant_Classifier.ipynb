{"cells":[{"metadata":{},"cell_type":"markdown","source":"Dataset --> https://www.kaggle.com/abdallahalidev/plantvillage-dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom PIL import Image\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.applications import MobileNet","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_PATH = '../input/plantvillage-dataset/color'\nBATCH_SIZE_PER_REPLICA = 32\ninput_shape = (256, 256, 3)\nclasses = 38","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import images\nBATCH_SIZE = 32\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  DATA_PATH,\n  validation_split=0.2,\n  label_mode='categorical',\n  seed = 123,\n  subset=\"training\",\n  image_size=(256, 256),\n  batch_size=BATCH_SIZE)\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  DATA_PATH,\n  validation_split=0.2,\n  label_mode='categorical',\n  seed = 123,\n  subset=\"validation\",\n  image_size=(256, 256),\n  batch_size=BATCH_SIZE)\n","execution_count":4,"outputs":[{"output_type":"stream","text":"Found 54305 files belonging to 38 classes.\nUsing 43444 files for training.\nFound 54305 files belonging to 38 classes.\nUsing 10861 files for validation.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nmodel = pickle.load(open('models/model.h5', 'rb'))\nmodel1 = pickle.load(open('models/model1.h5', 'rb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.python.client import device_lib\n\ntf.config.list_physical_devices()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_metrics(accuracy, loss, val_accuracy, val_loss, xlim):\n    fig, ax = plt.subplots(1, 2, figsize = (16, 7))\n\n    ax[0].plot([0]+accuracy, label = 'Accuracy')\n    ax[0].plot([0]+loss, label = 'Loss')\n    ax[0].set_title('Train')\n    ax[0].set(xlabel='epochs')\n    ax[0].set_xlim([1,xlim])\n    ax[0].grid(True)\n    ax[0].legend()\n\n    ax[1].plot([0]+val_accuracy, label = 'Accuracy')\n    ax[1].plot([0]+val_loss, label = 'Loss')\n    ax[1].set_title('Validation')\n    ax[1].set(xlabel='epochs')\n    ax[1].set_xlim([1,xlim])\n    ax[1].grid(True)\n    ax[1].legend()","execution_count":37,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1st model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def set_callbacks():\n    # initiate reduce learning rate class\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,\n                              patience=1, min_lr=0.0001)\n\n    #Early stop training\n    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2, verbose=1,\n        mode='auto', baseline=None, restore_best_weights=True)\n    \n    return [reduce_lr, early_stopping]","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fully_connected_layers(x):\n    x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n    x=Dropout(.2)(x)\n    x=Dense(1024,activation='relu')(x) #dense layer 2\n    x=Dropout(.2)(x)\n    x=Dense(512,activation='relu')(x) #dense layer 3\n    x=Dropout(.2)(x)\n    preds=Dense(classes,activation='softmax')(x) #final layer with softmax activation\n    return preds","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = (256, 256, 3)\nclasses = 38\n\nbase_model=MobileNet(input_shape = input_shape, weights='imagenet',include_top=False, pooling = 'avg') #imports the mobilenet model and discards the last 1000 neuron layer.\n\n# rescale images layer\n\nnew_input = tf.keras.Input(shape=(256, 256, 3))\nimage_rescale = keras.Sequential([\n        tf.keras.layers.experimental.preprocessing.Rescaling(scale = 1./255),\n    ])\nrescaled_images = image_rescale(new_input)\n\nx = base_model(rescaled_images) \n#x=Flatten(name='flatten')(base_model.output)\npreds = fully_connected_layers(x)\n\nmodel=Model(inputs=new_input,outputs=preds)\n\nfor layer in model.layers[2:3]:\n    layer.trainable=False\n\nmodel.summary()","execution_count":9,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n17227776/17225924 [==============================] - 0s 0us/step\nModel: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 256, 256, 3)]     0         \n_________________________________________________________________\nsequential (Sequential)      (None, 256, 256, 3)       0         \n_________________________________________________________________\nmobilenet_1.00_224 (Function (None, 1024)              3228864   \n_________________________________________________________________\ndense (Dense)                (None, 1024)              1049600   \n_________________________________________________________________\ndropout (Dropout)            (None, 1024)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1024)              1049600   \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 1024)              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 512)               524800    \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 38)                19494     \n=================================================================\nTotal params: 5,872,358\nTrainable params: 2,643,494\nNon-trainable params: 3,228,864\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Train model"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"batch_size = 32\nEPOCHS = 10\n\n# initiate RMSprop optimizer\nopt = keras.optimizers.RMSprop(lr=0.001, decay=1e-6)\n\ncallbacks = set_callbacks()\n\n# Let's train the model using RMSprop\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=opt,\n              metrics=['accuracy'])\n\n\nwith tf.device('/gpu:0'):\n    hist = model.fit(train_ds,\n                  #batch_size=batch_size,\n                  epochs=EPOCHS,\n                  validation_data=val_ds,\n                  callbacks = callbacks,\n                  shuffle=True)\n    \naccuracy, loss, val_accuracy, val_loss = hist.history['accuracy'], hist.history['loss'], hist.history['val_accuracy'], hist.history['val_loss'] \n","execution_count":19,"outputs":[{"output_type":"stream","text":"Epoch 1/2\n1358/1358 [==============================] - 452s 332ms/step - loss: 0.3985 - accuracy: 0.8923 - val_loss: 0.2939 - val_accuracy: 0.9278\nEpoch 2/2\n1358/1358 [==============================] - 139s 102ms/step - loss: 0.3094 - accuracy: 0.9255 - val_loss: 0.2625 - val_accuracy: 0.9353\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_metrics(accuracy, loss, val_accuracy, val_loss, EPOCHS)","execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1152x504 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('models/model.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2nd Model (with augmented images)"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model1=MobileNet(input_shape = input_shape, weights='imagenet',include_top=False, pooling = 'avg') #imports the mobilenet model and discards the last 1000 neuron layer.\n\n# augment images\n\nnew_input = tf.keras.Input(shape=(256, 256, 3))\ndata_augmentation = keras.Sequential([\n        tf.keras.layers.experimental.preprocessing.Rescaling(scale = 1./255),\n        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n        tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n        tf.keras.layers.experimental.preprocessing.RandomContrast(factor = 0.1)\n    ])\naugmented_images = data_augmentation(new_input)\n\nx = base_model1(augmented_images)  #new\n#x=Flatten(name='flatten')(base_model.output)\n\npreds = fully_connected_layers(x)\n\nmodel1=Model(inputs=new_input,outputs=preds)\n\n\nfor layer in model1.layers[2:3]:\n    layer.trainable=False\n\n\nmodel1.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Train model"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"batch_size = 32\nEPOCHS = 10\n\n# initiate RMSprop optimizer\nopt = keras.optimizers.RMSprop(lr=0.001, decay=1e-6)\n\ncallbacks = set_callbacks()\n\n\n# Let's train the model using RMSprop\nmodel1.compile(loss='categorical_crossentropy',\n              optimizer=opt,\n              metrics=['accuracy'])\n\nwith tf.device('/gpu:0'):\n    history_augm = model1.fit(train_ds,\n                  #batch_size=batch_size,\n                  epochs=EPOCHS,\n                  validation_data=val_ds,\n                  callbacks = callbacks,\n                  shuffle=True\n                             )\n\naccuracy, loss, val_accuracy, val_loss = history_augm.history['accuracy'], history_augm.history['loss'], history_augm.history['val_accuracy'], history_augm.history['val_loss'] \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_metrics(accuracy, loss, val_accuracy, val_loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.save('models/model1.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#LOSS\nloss = tf.keras.losses.SparseCategoricalCrossentropy()\n#ACCURACY\naccuracy = tf.keras.metrics.SparseCategoricalAccuracy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The two models have very close validation accuracies although the second model seems like it's less overfitted to the training data (lower training accuracy)"},{"metadata":{},"cell_type":"markdown","source":"#### Let's examine the first model a bit further"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"y_pred_prob = model.predict(val_ds)","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmax(y_pred_prob,axis=1)","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"array([30, 33, 29, ..., 37, 37, 37])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = []\nconf_matrix = np.zeros((38, 38), int)\nfor batch, labels in val_ds:\n    y_pred_class = np.argmax(model.predict(batch), axis = 1)\n    y_true_class = np.argmax(labels, axis = 1)\n    for pred_val, true_val in zip(y_pred_class, y_true_class):\n        conf_matrix[pred_val][true_val] += 1\n","execution_count":23,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's calculate the confussion matrix to see the model weaknesses"},{"metadata":{"trusted":true},"cell_type":"code","source":"n=38\n'{} correct predictions out of {} samples.'.format(sum(conf_matrix[i][i] for i in range(n)), '10861')","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"'10158 correct predictions out of 10861 samples.'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\nconf_matrix_df = pd.DataFrame(data = conf_matrix)\nconf_matrix_df.head(10)","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"    0    1   2    3    4    5    6   7    8    9   ...  28  29  30  31  32  \\\n0  105    0   0    0    0    1    0   0    0    0  ...   0   1   1   1   0   \n1    0  120   5    2    0    0    0   0    0    0  ...   0   0   0   0   0   \n2    0    0  47    0    0    0    0   0    0    0  ...   2   0   0   0   0   \n3   11    0   1  343    1    1    0   0    0    0  ...   1   0   0   0   0   \n4    1    0   0    0  316    0    0   0    0    0  ...   0   0   0   0   0   \n5    1    0   0    0    0  205    0   0    0    0  ...   0   0   0   0   0   \n6    0    2   0    1    0    0  147   0    0    0  ...   0   0   0   0   0   \n7    0    0   0    0    0    0    0  69    0    5  ...   0   0   0   0   0   \n8    0    0   0    0    0    0    0   0  238    0  ...   0   0   0   0   0   \n9    0    0   0    0    0    0    0  40    0  193  ...   1   0   0   0   0   \n\n   33  34  35  36  37  \n0   0   0   0   0   0  \n1   0   0   0   0   0  \n2   0   0   0   0   0  \n3   0   0   0   0   0  \n4   0   0   0   0   0  \n5   0   0   0   0   0  \n6   0   0   0   0   0  \n7   0   0   0   0   0  \n8   0   0   0   0   0  \n9   0   0   0   0   0  \n\n[10 rows x 38 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>28</th>\n      <th>29</th>\n      <th>30</th>\n      <th>31</th>\n      <th>32</th>\n      <th>33</th>\n      <th>34</th>\n      <th>35</th>\n      <th>36</th>\n      <th>37</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>105</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>120</td>\n      <td>5</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>47</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11</td>\n      <td>0</td>\n      <td>1</td>\n      <td>343</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>316</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>205</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>147</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>69</td>\n      <td>0</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>238</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>0</td>\n      <td>193</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows Ã— 38 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Rows correspond to the true values and columns to the predicted values"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\ndirectory = '../input/plantvillage-dataset/color'\nfolders = [x[0] for x in os.walk(directory)]","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maxval = 0\nfor row in range(38):\n    for col in range(38):\n        if(row!=col & conf_matrix[row][col] > maxval):\n            maxval = conf_matrix[row][col]\n            maxr = row\n            maxc = col\ntrue = folders[maxr + 1][len(directory)+1:]\nprediction = folders[maxc + 1][len(directory)+1:]     \n\n'We have misclassified {} times the {} as {}'.format(maxval, true, prediction)","execution_count":35,"outputs":[{"output_type":"execute_result","execution_count":35,"data":{"text/plain":"'We have misclassified 69 times the Corn_(maize)___Northern_Leaf_Blight as Corn_(maize)___Northern_Leaf_Blight'"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}